# âš¡ Fast Training Guide - Under 2 Hours

This guide explains how to train the Plant Leaf Disease Detection model in **under 2 hours** while maintaining high accuracy (92-95%).

## ðŸŽ¯ Quick Start

```bash
python train_model_fast.py
```

That's it! The script is fully optimized for speed.

## â±ï¸ Expected Training Time

- **Total Time**: 60-90 minutes (varies by GPU)
- **Phase 1 (Frozen Base)**: 25-35 minutes
- **Phase 2 (Fine-tuning)**: 35-55 minutes
- **Target**: Under 2 hours (120 minutes) âœ…

## ðŸ“Š Performance Trade-offs

| Model | Training Time | Accuracy | Image Size | Epochs |
|-------|--------------|----------|------------|--------|
| **Fast (New)** | **1-1.5 hours** | **92-95%** | **160x160** | **15** |
| MobileNetV2 | 2-3 hours | 93-95% | 224x224 | 50 |
| EfficientNetB3 | 3-5 hours | 95-97% | 300x300 | 50 |

## ðŸš€ Key Optimizations

### 1. **Reduced Image Size**
- Fast: 160x160 pixels (vs 224x224 or 300x300)
- Reduces computation by ~50% while maintaining good feature extraction

### 2. **Increased Batch Size**
- Fast: 64 (vs 32)
- Better GPU utilization, faster throughput
- Adjust to 32 or 48 if you have memory issues

### 3. **Reduced Epochs**
- Fast: 15 total epochs (8 + 7)
- Original: 50 epochs (20 + 30)
- 70% reduction with early stopping to prevent overfitting

### 4. **Mixed Precision Training**
- Uses `mixed_float16` for faster computation
- 2-3x speedup on modern GPUs
- Automatic in the script

### 5. **Lightweight Model**
- MobileNetV2 architecture
- Optimized for mobile/edge devices
- Good accuracy-to-speed ratio

### 6. **Streamlined Architecture**
- Simpler classification head (256 units vs 512+256)
- Less dropout for faster training
- Efficient layer freezing strategy

### 7. **Optimized Data Augmentation**
- Balanced augmentation (not excessive)
- Faster data pipeline
- Good generalization

## ðŸ“ˆ Expected Results

```
Test Accuracy: 92-95%
Top-3 Accuracy: 96-98%
Training Time: 60-90 minutes
```

### Accuracy by Training Method

- **Fast Training**: 92-95% (under 2 hours)
- **Standard MobileNetV2**: 93-95% (2-3 hours)
- **EfficientNetB3**: 95-97% (4-6 hours)

## ðŸ’» System Requirements

### Minimum (Slower Training)
- GPU: NVIDIA GTX 1060 or better
- RAM: 8GB
- CUDA: 11.0+
- Training Time: ~90 minutes

### Recommended (Faster Training)
- GPU: NVIDIA RTX 2060 or better
- RAM: 16GB
- CUDA: 11.2+
- Training Time: ~60 minutes

### Optimal (Fastest Training)
- GPU: NVIDIA RTX 3070 or better
- RAM: 16GB+
- CUDA: 11.8+
- Training Time: ~45 minutes

## ðŸ”§ Customization Options

### Adjust Batch Size for Your GPU

Edit `train_model_fast.py`:

```python
BATCH_SIZE = 64  # Default
# For 6GB GPU: BATCH_SIZE = 48
# For 4GB GPU: BATCH_SIZE = 32
# For 8GB+ GPU: BATCH_SIZE = 96 or 128
```

### Change Image Size

```python
IMG_SIZE = 160  # Default (fastest)
# IMG_SIZE = 128  # Even faster, slightly lower accuracy
# IMG_SIZE = 192  # Slower, slightly higher accuracy
```

### Adjust Training Epochs

```python
EPOCHS_PHASE1 = 8  # Frozen base training
EPOCHS_PHASE2 = 7  # Fine-tuning
# Reduce for faster training, increase for potentially better accuracy
```

## ðŸ“Š Training Metrics Tracked

The script saves detailed metrics to `models/training_stats_fast.json`:

```json
{
  "total_training_time_minutes": 75.5,
  "total_training_time_hours": 1.26,
  "phase1_time_minutes": 32.1,
  "phase2_time_minutes": 43.4,
  "total_epochs": 15,
  "test_accuracy": 0.9342,
  "test_top3_accuracy": 0.9756,
  "test_loss": 0.2134,
  "best_val_accuracy": 0.9389,
  "image_size": 160,
  "batch_size": 64,
  "model": "MobileNetV2",
  "mixed_precision": true
}
```

## ðŸ“ Output Files

After training completes:

```
models/
â”œâ”€â”€ best_model_fast_finetuned.h5    # Best model (USE THIS)
â”œâ”€â”€ final_model_fast.h5              # Final model
â”œâ”€â”€ class_indices_fast.json          # Class mappings
â””â”€â”€ training_stats_fast.json         # Training metrics

plots/
â””â”€â”€ training_history_fast.png        # Training curves

logs/
â””â”€â”€ fast_YYYYMMDD-HHMMSS/           # TensorBoard logs
```

## ðŸŽ¯ Usage After Training

### Make Predictions

```python
from predict import LeafDiseasePredictor

# Load the fast-trained model
predictor = LeafDiseasePredictor(
    model_path='models/best_model_fast_finetuned.h5',
    class_indices_path='models/class_indices_fast.json',
    img_size=160  # IMPORTANT: Match training size
)

# Predict
results = predictor.predict('test_image.jpg', top_k=5)
print(results)
```

Or use command line:

```bash
python predict.py test_image.jpg
```

### Evaluate Model

```bash
python evaluate_model.py
```

## ðŸ” Troubleshooting

### Out of Memory Error

**Solution 1**: Reduce batch size
```python
BATCH_SIZE = 32  # or even 16
```

**Solution 2**: Reduce image size
```python
IMG_SIZE = 128
```

**Solution 3**: Disable mixed precision
```python
# Comment out this line:
# set_global_policy('mixed_float16')
```

### Training Too Slow (>2 hours)

**Check GPU Usage**:
```bash
nvidia-smi
watch -n 1 nvidia-smi
```

**Verify GPU is being used**:
```python
import tensorflow as tf
print("GPUs Available:", tf.config.list_physical_devices('GPU'))
```

**Speed up further**:
- Increase batch size: `BATCH_SIZE = 96` or `128`
- Reduce image size: `IMG_SIZE = 128`
- Reduce epochs: `EPOCHS_PHASE1 = 6`, `EPOCHS_PHASE2 = 5`

### Lower Accuracy Than Expected

**If accuracy is <90%**:
1. Train for a few more epochs
2. Increase image size to 192
3. Check data augmentation parameters
4. Ensure dataset is properly organized

**Normal accuracy range**: 92-95%

## ðŸ“Š Comparison Chart

| Aspect | Fast Training | Standard Training |
|--------|--------------|------------------|
| Training Time | 1-1.5 hours | 3-5 hours |
| Test Accuracy | 92-95% | 95-97% |
| Image Size | 160x160 | 300x300 |
| Batch Size | 64 | 32 |
| Epochs | 15 | 50 |
| Model | MobileNetV2 | EfficientNetB3 |
| Mixed Precision | âœ… Yes | âŒ No |
| GPU Memory | ~4-6GB | ~8-12GB |
| Use Case | Quick iteration, testing | Production, max accuracy |

## ðŸ’¡ Best Practices

1. **Start with Fast Training**
   - Validate your dataset
   - Test your pipeline
   - Quick experiments

2. **Monitor Training**
   ```bash
   # In another terminal
   tensorboard --logdir logs/
   ```

3. **Check Results**
   - View `plots/training_history_fast.png`
   - Check `models/training_stats_fast.json`
   - Evaluate with `evaluate_model.py`

4. **Use Best Model**
   - Always use `best_model_fast_finetuned.h5` for inference
   - It has the best validation accuracy

5. **Iterate Quickly**
   - Fast training lets you experiment more
   - Try different augmentations
   - Test hyperparameters

## ðŸŽ“ When to Use Each Model

### Use Fast Training When:
- âœ… You need results quickly (< 2 hours)
- âœ… Prototyping and testing
- âœ… Limited GPU resources
- âœ… 92-95% accuracy is sufficient
- âœ… Deploying to mobile/edge devices
- âœ… Quick iterations needed

### Use Standard Training When:
- âœ… You need maximum accuracy (95-97%)
- âœ… Final production model
- âœ… Time is not a constraint
- âœ… You have powerful GPU
- âœ… Research or publication

## ðŸ“š Additional Resources

- **Main Documentation**: `README_MODEL.md`
- **Quick Reference**: `QUICK_REFERENCE.md`
- **Model Comparison**: `model_comparison.py`
- **Setup Check**: `check_setup.py`

## ðŸ¤ Need Help?

If training takes longer than 2 hours or accuracy is below 90%, check:
1. GPU is properly configured
2. Dataset is complete and valid
3. Batch size matches your GPU memory
4. No background processes consuming GPU

## âš¡ Summary

Fast training provides:
- âœ… **60-90 minute training time**
- âœ… **92-95% accuracy**
- âœ… **Same prediction interface**
- âœ… **Smaller model size**
- âœ… **Lower GPU memory usage**
- âœ… **Perfect for quick iteration**

Start training now:
```bash
python train_model_fast.py
```

---

**Happy Fast Training! ðŸš€ðŸŒ¿**
